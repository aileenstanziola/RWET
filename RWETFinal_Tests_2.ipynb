{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_ft = open(\"figtree.txt\").read().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'abottomlesspitofselfloathing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "initials_ft = {}\n",
    "for item in words_ft:\n",
    "    first_let = item[0]\n",
    "    if first_let in initials_ft:\n",
    "        initials_ft[first_let].append(item)\n",
    "    else: \n",
    "        initials_ft[first_let] = []\n",
    "        initials_ft[first_let].append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "but\n",
      "out\n",
      "there,\n",
      "tip\n",
      "out\n",
      "more\n",
      "life\n",
      "every\n",
      "saw\n",
      "starving\n",
      "purple\n",
      "in\n",
      "to\n",
      "of\n",
      "fig\n",
      "saw\n",
      "each\n",
      "lovers\n",
      "fig\n",
      "lady\n",
      "out.\n",
      "another\n",
      "this\n",
      "home\n",
      "in\n",
      "names\n",
      "ground\n"
     ]
    }
   ],
   "source": [
    "for ch in seed:\n",
    "    print(random.choice(initials_ft[ch]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "another branching of the tip of make lady each starving saw plopped in to of fig saw editor, lovers fig life one, a tree happy in names green\n"
     ]
    }
   ],
   "source": [
    "print (\" \".join([random.choice(initials_ft[ch])for ch in seed]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "another branch, of this tree, one, my lovers each saw starving pack in to offbeat fig sitting every like fig like one a these husband in names go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tracery\n",
    "from tracery.modifiers import base_english"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# excerpt 'the fig tree' (shorter source text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I I ['I']\n",
      "saw s ['saw']\n",
      "my m ['my']\n",
      "life l ['life']\n",
      "branching b ['branching']\n",
      "out o ['out']\n",
      "before b ['branching', 'before']\n",
      "me m ['my', 'me']\n",
      "like l ['life', 'like']\n",
      "the t ['the']\n",
      "green g ['green']\n",
      "fig f ['fig']\n",
      "tree t ['the', 'tree']\n",
      "in i ['in']\n",
      "the t ['the', 'tree', 'the']\n",
      "story. s ['saw', 'story.']\n",
      "From F ['From']\n",
      "the t ['the', 'tree', 'the', 'the']\n",
      "tip t ['the', 'tree', 'the', 'the', 'tip']\n",
      "of o ['out', 'of']\n",
      "every e ['every']\n",
      "branch, b ['branching', 'before', 'branch,']\n",
      "like l ['life', 'like', 'like']\n",
      "a a ['a']\n",
      "fat f ['fig', 'fat']\n",
      "purple p ['purple']\n",
      "fig, f ['fig', 'fat', 'fig,']\n",
      "a a ['a', 'a']\n",
      "wonderful w ['wonderful']\n",
      "future f ['fig', 'fat', 'fig,', 'future']\n",
      "beckoned b ['branching', 'before', 'branch,', 'beckoned']\n",
      "and a ['a', 'a', 'and']\n",
      "winked. w ['wonderful', 'winked.']\n",
      "One O ['One']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was']\n",
      "a a ['a', 'a', 'and', 'a']\n",
      "husband h ['husband']\n",
      "and a ['a', 'a', 'and', 'a', 'and']\n",
      "a a ['a', 'a', 'and', 'a', 'and', 'a']\n",
      "happy h ['husband', 'happy']\n",
      "home h ['husband', 'happy', 'home']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and']\n",
      "children, c ['children,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was']\n",
      "a a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a']\n",
      "famous f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous']\n",
      "poet p ['purple', 'poet']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was', 'was']\n",
      "a a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a']\n",
      "brilliant b ['branching', 'before', 'branch,', 'beckoned', 'brilliant']\n",
      "professor, p ['purple', 'poet', 'professor,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was', 'was', 'was']\n",
      "Ee E ['Ee']\n",
      "Gee, G ['Gee,']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the']\n",
      "amazing a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing']\n",
      "editor, e ['every', 'editor,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was']\n",
      "Europe E ['Ee', 'Europe']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and']\n",
      "Africa A ['Africa']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and']\n",
      "South S ['South']\n",
      "America, A ['Africa', 'America,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was']\n",
      "Constantin C ['Constantin']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and']\n",
      "Socrates S ['South', 'Socrates']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and']\n",
      "Attila A ['Africa', 'America,', 'Attila']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and']\n",
      "a a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a']\n",
      "pack p ['purple', 'poet', 'professor,', 'pack']\n",
      "of o ['out', 'of', 'of']\n",
      "other o ['out', 'of', 'of', 'other']\n",
      "lovers l ['life', 'like', 'like', 'lovers']\n",
      "with w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with']\n",
      "queer q ['queer']\n",
      "names n ['names']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and']\n",
      "offbeat o ['out', 'of', 'of', 'other', 'offbeat']\n",
      "professions, p ['purple', 'poet', 'professor,', 'pack', 'professions,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and']\n",
      "another a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig']\n",
      "was w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was']\n",
      "an a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an']\n",
      "Olympic O ['One', 'Olympic']\n",
      "lady l ['life', 'like', 'like', 'lovers', 'lady']\n",
      "crew c ['children,', 'crew']\n",
      "champion, c ['children,', 'crew', 'champion,']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and']\n",
      "beyond b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and']\n",
      "above a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above']\n",
      "these t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these']\n",
      "figs f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs']\n",
      "were w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was', 'were']\n",
      "many m ['my', 'me', 'many']\n",
      "more m ['my', 'me', 'many', 'more']\n",
      "figs f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs', 'figs']\n",
      "I I ['I', 'I']\n",
      "couldn't c ['children,', 'crew', 'champion,', \"couldn't\"]\n",
      "quite q ['queer', 'quite']\n",
      "make m ['my', 'me', 'many', 'more', 'make']\n",
      "out. o ['out', 'of', 'of', 'other', 'offbeat', 'out.']\n",
      "I I ['I', 'I', 'I']\n",
      "saw s ['saw', 'story.', 'saw']\n",
      "myself m ['my', 'me', 'many', 'more', 'make', 'myself']\n",
      "sitting s ['saw', 'story.', 'saw', 'sitting']\n",
      "in i ['in', 'in']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the']\n",
      "crotch c ['children,', 'crew', 'champion,', \"couldn't\", 'crotch']\n",
      "of o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of']\n",
      "this t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this']\n",
      "fig f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs', 'figs', 'fig']\n",
      "tree, t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,']\n",
      "starving s ['saw', 'story.', 'saw', 'sitting', 'starving']\n",
      "to t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to']\n",
      "death, d ['death,']\n",
      "just j ['just']\n",
      "because b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond', 'because']\n",
      "I I ['I', 'I', 'I', 'I']\n",
      "couldn't c ['children,', 'crew', 'champion,', \"couldn't\", 'crotch', \"couldn't\"]\n",
      "make m ['my', 'me', 'many', 'more', 'make', 'myself', 'make']\n",
      "up u ['up']\n",
      "my m ['my', 'me', 'many', 'more', 'make', 'myself', 'make', 'my']\n",
      "mind m ['my', 'me', 'many', 'more', 'make', 'myself', 'make', 'my', 'mind']\n",
      "which w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was', 'were', 'which']\n",
      "of o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the']\n",
      "figs f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs', 'figs', 'fig', 'figs']\n",
      "I I ['I', 'I', 'I', 'I', 'I']\n",
      "would w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was', 'were', 'which', 'would']\n",
      "choose. c ['children,', 'crew', 'champion,', \"couldn't\", 'crotch', \"couldn't\", 'choose.']\n",
      "I I ['I', 'I', 'I', 'I', 'I', 'I']\n",
      "wanted w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was', 'were', 'which', 'would', 'wanted']\n",
      "each e ['every', 'editor,', 'each']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and']\n",
      "every e ['every', 'editor,', 'each', 'every']\n",
      "one o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of', 'one']\n",
      "of o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of', 'one', 'of']\n",
      "them, t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,']\n",
      "but b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond', 'because', 'but']\n",
      "choosing c ['children,', 'crew', 'champion,', \"couldn't\", 'crotch', \"couldn't\", 'choose.', 'choosing']\n",
      "one o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of', 'one', 'of', 'one']\n",
      "meant m ['my', 'me', 'many', 'more', 'make', 'myself', 'make', 'my', 'mind', 'meant']\n",
      "losing l ['life', 'like', 'like', 'lovers', 'lady', 'losing']\n",
      "all a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the']\n",
      "rest, r ['rest,']\n",
      "and, a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all', 'and,']\n",
      "as a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all', 'and,', 'as']\n",
      "I I ['I', 'I', 'I', 'I', 'I', 'I', 'I']\n",
      "sat s ['saw', 'story.', 'saw', 'sitting', 'starving', 'sat']\n",
      "there, t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,']\n",
      "unable u ['up', 'unable']\n",
      "to t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to']\n",
      "decide, d ['death,', 'decide,']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to', 'the']\n",
      "figs f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs', 'figs', 'fig', 'figs', 'figs']\n",
      "began b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond', 'because', 'but', 'began']\n",
      "to t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to', 'the', 'to']\n",
      "wrinkle w ['wonderful', 'winked.', 'was', 'was', 'was', 'was', 'was', 'was', 'with', 'was', 'were', 'which', 'would', 'wanted', 'wrinkle']\n",
      "and a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all', 'and,', 'as', 'and']\n",
      "go g ['green', 'go']\n",
      "black, b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond', 'because', 'but', 'began', 'black,']\n",
      "and, a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all', 'and,', 'as', 'and', 'and,']\n",
      "one o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of', 'one', 'of', 'one', 'one']\n",
      "by b ['branching', 'before', 'branch,', 'beckoned', 'brilliant', 'beyond', 'because', 'but', 'began', 'black,', 'by']\n",
      "one, o ['out', 'of', 'of', 'other', 'offbeat', 'out.', 'of', 'of', 'one', 'of', 'one', 'one', 'one,']\n",
      "they t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to', 'the', 'to', 'they']\n",
      "plopped p ['purple', 'poet', 'professor,', 'pack', 'professions,', 'plopped']\n",
      "to t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to', 'the', 'to', 'they', 'to']\n",
      "the t ['the', 'tree', 'the', 'the', 'tip', 'the', 'these', 'the', 'this', 'tree,', 'to', 'the', 'them,', 'the', 'there,', 'to', 'the', 'to', 'they', 'to', 'the']\n",
      "ground g ['green', 'go', 'ground']\n",
      "at a ['a', 'a', 'and', 'a', 'and', 'a', 'and', 'and', 'another', 'a', 'and', 'another', 'a', 'and', 'another', 'amazing', 'and', 'another', 'and', 'and', 'and', 'another', 'and', 'and', 'and', 'a', 'and', 'and', 'another', 'an', 'and', 'and', 'above', 'and', 'all', 'and,', 'as', 'and', 'and,', 'at']\n",
      "my m ['my', 'me', 'many', 'more', 'make', 'myself', 'make', 'my', 'mind', 'meant', 'my']\n",
      "feet. f ['fig', 'fat', 'fig,', 'future', 'fig', 'fig', 'famous', 'fig', 'fig', 'fig', 'fig', 'fig', 'figs', 'figs', 'fig', 'figs', 'figs', 'feet.']\n"
     ]
    }
   ],
   "source": [
    "words_ft = open(\"figtree.txt\").read().split() # read in a text file, split into words\n",
    "initials_ft = {} # create an empty dictionary\n",
    "\n",
    "for item in words_ft: # run this code for every word in the text\n",
    "    \n",
    "    first_let = item[0] # first_let now has the first character of the string\n",
    "    \n",
    "    # check to see if the letter is already a key in the dictionary.\n",
    "    # if not, add a new key/value pair with an empty list as the value.\n",
    "    if first_let not in initials_ft:\n",
    "        initials_ft[first_let] = []\n",
    "        \n",
    "    # append the current word to the list that is the value for this key\n",
    "    initials_ft[first_let].append(item)\n",
    "    \n",
    "    # uncomment line below to see debug output\n",
    "    print(item, first_let, initials_ft[first_let])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_words_ft = [item for item in words_ft if item.lower().startswith('a')]\n",
    "b_words_ft = [item for item in words_ft if item.lower().startswith('b')]\n",
    "o_words_ft = [item for item in words_ft if item.lower().startswith('o')]\n",
    "t_words_ft = [item for item in words_ft if item.lower().startswith('t')]\n",
    "m_words_ft = [item for item in words_ft if item.lower().startswith('m')]\n",
    "l_words_ft = [item for item in words_ft if item.lower().startswith('l')]\n",
    "e_words_ft = [item for item in words_ft if item.lower().startswith('e')]\n",
    "s_words_ft = [item for item in words_ft if item.lower().startswith('s')]\n",
    "p_words_ft = [item for item in words_ft if item.lower().startswith('p')]\n",
    "i_words_ft = [item for item in words_ft if item.lower().startswith('i')]\n",
    "f_words_ft = [item for item in words_ft if item.lower().startswith('f')]\n",
    "h_words_ft = [item for item in words_ft if item.lower().startswith('h')]\n",
    "n_words_ft = [item for item in words_ft if item.lower().startswith('n')]\n",
    "g_words_ft = [item for item in words_ft if item.lower().startswith('g')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      "brilliant of there, the Olympic me like every Socrates saw\n",
      "purple I to\n",
      "of fig\n",
      "saw Ee like fig, - life One another the home I names green.\n",
      "\n",
      "all\n",
      "branch, out to to out myself like editor, starving saw\n",
      "purple in tree,\n",
      "of fig\n",
      "South every life fig - like one and, tree happy in names go.\n",
      "\n",
      "an\n",
      "beckoned one the tree, one mind lady each starving sat\n",
      "purple I to\n",
      "one fig\n",
      "Socrates Europe lady fig - lady of a to home in names ground.\n",
      "\n",
      "another\n",
      "black, of to the One my like editor, saw Socrates\n",
      "pack in tip\n",
      "out fig\n",
      "starving every lovers fig - losing one Attila the home I names Gee,.\n",
      "\n",
      "a\n",
      "before of them, they of more losing every saw saw\n",
      "pack I the\n",
      "out. fig\n",
      "South each like fig - lady of and these happy I names Gee,.\n",
      "\n",
      "a\n",
      "because out the to of my like Europe saw Socrates\n",
      "professions, in tree,\n",
      "of fig,\n",
      "Socrates Ee losing fig - like of and the happy I names Gee,.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "        \"origin\": \"#a_words_ft#\\n#b_words_ft# #o_words_ft# #t_words_ft# #t_words_ft# #o_words_ft# #m_words_ft# #l_words_ft# #e_words_ft# #s_words_ft# #s_words_ft#\\n#p_words_ft# #i_words_ft# #t_words_ft#\\n#o_words_ft# #f_words_ft#\\n#s_words_ft# #e_words_ft# #l_words_ft# #f_words_ft# - #l_words_ft# #o_words_ft# #a_words_ft# #t_words_ft# #h_words_ft# #i_words_ft# #n_words_ft# #g_words_ft#.\"\n",
    "    ,\n",
    "        \"a_words_ft\": a_words_ft, \n",
    "        \"b_words_ft\": b_words_ft,\n",
    "        \"o_words_ft\": o_words_ft,\n",
    "        \"t_words_ft\": t_words_ft,\n",
    "        \"m_words_ft\": m_words_ft,\n",
    "        \"l_words_ft\": l_words_ft,\n",
    "        \"e_words_ft\": e_words_ft,\n",
    "        \"s_words_ft\": s_words_ft,\n",
    "        \"p_words_ft\": p_words_ft, \n",
    "        \"i_words_ft\": i_words_ft,\n",
    "        \"f_words_ft\": f_words_ft,\n",
    "        \"h_words_ft\": h_words_ft,\n",
    "        \"n_words_ft\": n_words_ft,\n",
    "        \"g_words_ft\": g_words_ft\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "by beyond\n",
      "of of One\n",
      "the the the the\n",
      "the the the the to\n",
      "one one, out. of Olympic Olympic\n",
      "more many my make make more make\n",
      "life lovers life lady losing lovers life life\n",
      "every Ee every every editor, each Europe each each\n",
      "South story. story. saw story. saw story. Socrates starving story.\n",
      "saw sat saw sat Socrates story. South saw sat South saw\n",
      "professions, plopped professions, pack poet pack professions, pack pack professions, professions, professor,\n",
      "I in I I I I I in I I I I I\n",
      "the to tip these the the the the the this these the to tip\n",
      "of one One out. of of of one of one one out. one one of\n",
      "fig, figs fig fig figs figs famous future fig fat fig figs feet. fig future From\n",
      "story. sitting sitting saw South South Socrates South saw sat saw sat sat South story. starving saw\n",
      "each Europe every every each Ee editor, every each editor, every editor, editor, editor, Ee Ee every Europe\n",
      "losing lovers like losing like life like like lovers lady like life lady lady lovers losing losing like like\n",
      "fig fig fig feet. figs figs figs figs figs fig fat fig From figs fig figs famous fig fat fig\n",
      " - \n",
      "like life life losing lovers like life losing lady lady lovers losing lovers lovers lovers lady losing life losing losing losing\n",
      "one, one Olympic other of one, one one other One one offbeat of of of one of out of out of out\n",
      "Attila and a and and amazing a and and and and at and and, a a another another another and above and a\n",
      "the the there, to the the tree the the to the the the the them, the tree, them, they to tree, them, the the\n",
      "I I I I I in I I I in I I I I I in I I in I I I in I in\n",
      "names names names names names names names names names names names names names names names names names names names names names names names names names names names\n",
      "green ground Gee, ground green green green ground green Gee, green Gee, Gee, Gee, ground green ground ground green green Gee, ground Gee, go green green ground.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "        \"origin\": \"#a_words_ft#\\n#b_words_ft# #b_words_ft#\\n#o_words_ft# #o_words_ft# #o_words_ft#\\n#t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft#\\n#t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft#\\n#o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft#\\n#m_words_ft# #m_words_ft# #m_words_ft# #m_words_ft# #m_words_ft# #m_words_ft# #m_words_ft#\\n#l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft#\\n#e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft#\\n#s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft#\\n#s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft#\\n#p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft# #p_words_ft#\\n#i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft#\\n#t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft#\\n#o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft#\\n#f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft#\\n#s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft# #s_words_ft#\\n#e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft# #e_words_ft#\\n#l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft#\\n#f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft# #f_words_ft#\\n - \\n#l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft# #l_words_ft#\\n#o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft# #o_words_ft#\\n#a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft# #a_words_ft#\\n#t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft# #t_words_ft#\\n#i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft# #i_words_ft#\\n#n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft# #n_words_ft#\\n#g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft# #g_words_ft#.\"\n",
    "    ,\n",
    "        \"a_words_ft\": a_words_ft, \n",
    "        \"b_words_ft\": b_words_ft,\n",
    "        \"o_words_ft\": o_words_ft,\n",
    "        \"t_words_ft\": t_words_ft,\n",
    "        \"m_words_ft\": m_words_ft,\n",
    "        \"l_words_ft\": l_words_ft,\n",
    "        \"e_words_ft\": e_words_ft,\n",
    "        \"s_words_ft\": s_words_ft,\n",
    "        \"p_words_ft\": p_words_ft, \n",
    "        \"i_words_ft\": i_words_ft,\n",
    "        \"f_words_ft\": f_words_ft,\n",
    "        \"h_words_ft\": h_words_ft,\n",
    "        \"n_words_ft\": n_words_ft,\n",
    "        \"g_words_ft\": g_words_ft\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "before one the the of meant life each story. starving\n",
      "pack in the\n",
      "of figs\n",
      "saw every lady fig - like out. a to home in names ground.\n",
      "\n",
      "and\n",
      "black, one the this of me losing each sitting sitting\n",
      "pack in there,\n",
      "offbeat figs\n",
      "sitting every life fig - losing one and to happy in names go.\n",
      "\n",
      "and\n",
      "beyond of the tip one more lovers every saw saw\n",
      "plopped in they\n",
      "of fig\n",
      "story. every life feet. - lovers out an them, happy in names go.\n",
      "\n",
      "above\n",
      "but one the they one make like each saw saw\n",
      "professions, in to\n",
      "of figs\n",
      "saw each like famous - lady of a the happy in names ground.\n",
      "\n",
      "as\n",
      "brilliant out. there, the one my like each saw saw\n",
      "pack in the\n",
      "of fig\n",
      "saw every life figs - like other a the happy in names go.\n",
      "\n",
      "a\n",
      "because offbeat them, the of make life editor, story. starving\n",
      "poet in the\n",
      "one, fig,\n",
      "saw every like figs - lovers of and the husband in names ground.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "        \"origin\": \"#a_words#\\n#b_words# #o_words# #t_words# #t_words# #o_words# #m_words# #l_words# #e_words# #s_words# #s_words#\\n#p_words# #i_words# #t_words#\\n#o_words# #f_words#\\n#s_words# #e_words# #l_words# #f_words# - #l_words# #o_words# #a_words# #t_words# #h_words# #i_words# #n_words# #g_words#.\"\n",
    "    ,\n",
    "        \"a_words\": initials_ft['a'], \n",
    "        \"b_words\": initials_ft['b'],\n",
    "        \"o_words\": initials_ft['o'],\n",
    "        \"t_words\": initials_ft['t'],\n",
    "        \"m_words\": initials_ft['m'],\n",
    "        \"l_words\": initials_ft['l'],\n",
    "        \"e_words\": initials_ft['e'],\n",
    "        \"s_words\": initials_ft['s'],\n",
    "        \"p_words\": initials_ft['p'], \n",
    "        \"i_words\": initials_ft['i'],\n",
    "        \"f_words\": initials_ft['f'],\n",
    "        \"h_words\": initials_ft['h'],\n",
    "        \"n_words\": initials_ft['n'],\n",
    "        \"g_words\": initials_ft['g']\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the bell jar complete book (longer source text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_bj = open(\"the_bell_jar.txt\").read().split() # read in a text file, split into words\n",
    "initials_bj = {} # create an empty dictionary\n",
    "\n",
    "for item in words_bj: # run this code for every word in the text\n",
    "    \n",
    "    first_let = item[0] # first_let now has the first character of the string\n",
    "    \n",
    "    # check to see if the letter is already a key in the dictionary.\n",
    "    # if not, add a new key/value pair with an empty list as the value.\n",
    "    if first_let not in initials_bj:\n",
    "        initials_bj[first_let] = []\n",
    "        \n",
    "    # append the current word to the list that is the value for this key\n",
    "    initials_bj[first_let].append(item)\n",
    "    \n",
    "    # uncomment line below to see debug output\n",
    "    #print(item, first_let, initials_bj[first_let])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_words_bj = [item for item in words_bj if item.lower().startswith('a')]\n",
    "b_words_bj = [item for item in words_bj if item.lower().startswith('b')]\n",
    "o_words_bj = [item for item in words_bj if item.lower().startswith('o')]\n",
    "t_words_bj = [item for item in words_bj if item.lower().startswith('t')]\n",
    "m_words_bj = [item for item in words_bj if item.lower().startswith('m')]\n",
    "l_words_bj = [item for item in words_bj if item.lower().startswith('l')]\n",
    "e_words_bj = [item for item in words_bj if item.lower().startswith('e')]\n",
    "s_words_bj = [item for item in words_bj if item.lower().startswith('s')]\n",
    "p_words_bj = [item for item in words_bj if item.lower().startswith('p')]\n",
    "i_words_bj = [item for item in words_bj if item.lower().startswith('i')]\n",
    "f_words_bj = [item for item in words_bj if item.lower().startswith('f')]\n",
    "h_words_bj = [item for item in words_bj if item.lower().startswith('h')]\n",
    "n_words_bj = [item for item in words_bj if item.lower().startswith('n')]\n",
    "g_words_bj = [item for item in words_bj if item.lower().startswith('g')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code for getting the first word in order (sort of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "but\n",
      "of\n",
      "that's\n",
      "there\n",
      "of\n",
      "morning\n",
      "life.\n",
      "eyes\n",
      "seeped\n",
      "sweet\n",
      "prize\n",
      "in\n",
      "the\n",
      "outside\n",
      "from\n",
      "soon\n",
      "essays\n",
      "lipsticks\n",
      "fashion\n",
      "long\n",
      "out\n",
      "and\n",
      "tops\n",
      "hair\n",
      "in,\n",
      "naked\n",
      "girls\n"
     ]
    }
   ],
   "source": [
    "#print(initials_bj['a'][0])\n",
    "#print(initials_bj['b'][0],initials_bj['o'][0] )\n",
    "\n",
    "count=0\n",
    "for ch in seed:\n",
    "    print(initials_bj[ch][count])\n",
    "    count = count +1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_phonemes: ['uhh',\n",
    " 'i.',\n",
    " 'aah',\n",
    " 'aue',\n",
    " 'eh',\n",
    " 'ae',\n",
    " 'ee',\n",
    " 'oie',\n",
    " 'ilya',\n",
    " 'aw',\n",
    " 'eure',\n",
    " 'oooh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "but_phonemes: ['butt',\n",
    " 'butsch',\n",
    " 'buc',\n",
    " 'bupp',\n",
    " 'gutt',\n",
    " 'buttock',\n",
    " 'budde',\n",
    " 'dutt',\n",
    " 'duk',\n",
    " \"but's\",\n",
    " 'bugge',\n",
    " 'bubb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "of_phonemes: ['of',\n",
    " \"eva's\",\n",
    " 'ovens',\n",
    " \"eva's\",\n",
    " 'oven',\n",
    " 'uthe',\n",
    " 'iva',\n",
    " 'ivens',\n",
    " \"avana's\",\n",
    " 'aversive',\n",
    " 'lovage',\n",
    " \"avon's\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "there_phonemes: [\"they're\",\n",
    " 'zehr',\n",
    " 'gehr',\n",
    " 'jerez',\n",
    " 'geniere',\n",
    " \"there's\",\n",
    " \"they'll\",\n",
    " 'zayre',\n",
    " 'dezern',\n",
    " \"there'd\",\n",
    " 'pres',\n",
    " 'zelle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "morning_phonemes: ['mourning',\n",
    " 'midmorning',\n",
    " 'moehring',\n",
    " 'yawning',\n",
    " 'norling',\n",
    " 'mooring',\n",
    " \"morning's\",\n",
    " 'mailroom',\n",
    " 'morn',\n",
    " 'moaning',\n",
    " 'moines',\n",
    " 'norming']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_phonemes: ['life',\n",
    " \"life's\",\n",
    " 'live',\n",
    " 'knife',\n",
    " 'rife',\n",
    " 'laff',\n",
    " 'leifheit',\n",
    " 'slife',\n",
    " 'leifeste',\n",
    " 'lifelike',\n",
    " 'refile',\n",
    " 'saif']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eyes_phonemes: [\"eye's\",\n",
    " 'ige',\n",
    " 'as',\n",
    " 'ice',\n",
    " 'is',\n",
    " 'incise',\n",
    " 'ices',\n",
    " 'aus',\n",
    " \"allies'\",\n",
    " \"a.'s\",\n",
    " 'isaacs',\n",
    " 'edythe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeped_phonemes: ['seeped',\n",
    " 'speech',\n",
    " 'speece',\n",
    " 'spaeth',\n",
    " 'steeped',\n",
    " 'speake',\n",
    " 'speed',\n",
    " 'seip',\n",
    " 'respeak',\n",
    " 'peeped',\n",
    " 'spease',\n",
    " 'reaped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweet_phonemes: ['sweatt',\n",
    " 'thweatt',\n",
    " 'swiech',\n",
    " 'tweet',\n",
    " 'sweep',\n",
    " 'swede',\n",
    " 'swett',\n",
    " 'tweed',\n",
    " 'suisse',\n",
    " 'switch',\n",
    " 'suites',\n",
    " 'schwede']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prize_phonemes: ['pries',\n",
    " 'preiss',\n",
    " 'pryde',\n",
    " 'plies',\n",
    " 'prizes',\n",
    " \"price's\",\n",
    " 'krise',\n",
    " 'preside',\n",
    " 'pruyn',\n",
    " 'priced',\n",
    " \"fry's\",\n",
    " 'tries']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_phonemes: ['in.',\n",
    " 'aine',\n",
    " 'inane',\n",
    " 'ein',\n",
    " 'n.',\n",
    " 'inning',\n",
    " 'emlyn',\n",
    " 'imm',\n",
    " 'ahn',\n",
    " 'ame',\n",
    " 'emme',\n",
    " 'engh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_phonemes: ['the',\n",
    " 'ertha',\n",
    " 'otha',\n",
    " 'leitha',\n",
    " 'suther',\n",
    " 'yother',\n",
    " 'uther',\n",
    " 'thy',\n",
    " 'nother',\n",
    " 'futher',\n",
    " 'rather',\n",
    " 'uthe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outside_phonemes: ['outside',\n",
    " 'outsize',\n",
    " 'outsides',\n",
    " 'outsider',\n",
    " 'outshine',\n",
    " 'outsized',\n",
    " 'outright',\n",
    " 'outshines',\n",
    " 'alcide',\n",
    " \"outsider's\",\n",
    " 'upside-down',\n",
    " 'eyesight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from_phonemes: ['frum',\n",
    " 'schrum',\n",
    " 'pflum',\n",
    " 'freiman',\n",
    " 'freemon',\n",
    " 'thrun',\n",
    " 'freyman',\n",
    " 'frumkin',\n",
    " 'frump',\n",
    " 'threemonth',\n",
    " 'flung',\n",
    " 'fleeman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soon_phonemes: ['suen',\n",
    " 'choon',\n",
    " 'thune',\n",
    " 'soong',\n",
    " 'suhm',\n",
    " 'suon',\n",
    " \"soonyi's\",\n",
    " 'sunau',\n",
    " 'noose',\n",
    " 'susumu',\n",
    " 'suny',\n",
    " 'soonyi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essays_phonemes: ['essays',\n",
    " \"s's\",\n",
    " 'aces',\n",
    " 'assesses',\n",
    " 'etches',\n",
    " 'excesses',\n",
    " 'essay',\n",
    " 'excesses',\n",
    " 'yeses',\n",
    " \"h's\",\n",
    " 'obsesses',\n",
    " 'ace']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lipstick_phonemes: ['lipstick',\n",
    " 'dipstick',\n",
    " 'lipsticks',\n",
    " 'slapstick',\n",
    " 'nitpick',\n",
    " 'lipsitz',\n",
    " 'pitstick',\n",
    " 'spitz',\n",
    " 'spic',\n",
    " 'spastic',\n",
    " 'stick',\n",
    " 'lipsig']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_phonemes: ['fashion',\n",
    " 'fashioned',\n",
    " 'fascination',\n",
    " \"fashion's\",\n",
    " 'fashioning',\n",
    " 'paschen',\n",
    " 'faction',\n",
    " 'cashen',\n",
    " 'ashen',\n",
    " 'phoenician',\n",
    " 'fasching',\n",
    " 'shaff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_phonemes: ['long',\n",
    " 'leung',\n",
    " 'loong',\n",
    " 'laun',\n",
    " 'oolong',\n",
    " 'nall',\n",
    " 'loom',\n",
    " 'newall',\n",
    " 'lall',\n",
    " 'loon',\n",
    " 'luminol',\n",
    " 'longmore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_phonemes: ['out',\n",
    " 'ouch',\n",
    " 'outright',\n",
    " 'outpouch',\n",
    " \"out's\",\n",
    " 'output',\n",
    " 'outlook',\n",
    " 'outta',\n",
    " 'outed',\n",
    " 'tout',\n",
    " 'auten',\n",
    " 'eide']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "and_phonemes: ['und',\n",
    " 'unland',\n",
    " 'anand',\n",
    " 'umland',\n",
    " 'edlund',\n",
    " 'edmond',\n",
    " 'ende',\n",
    " 'undreamed',\n",
    " 'unbend',\n",
    " 'emond',\n",
    " 'odland',\n",
    " 'ireland']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tops_phonemes: ['topps',\n",
    " 'topped',\n",
    " 'chops',\n",
    " 'spot',\n",
    " 'spotts',\n",
    " 'copps',\n",
    " 'laptops',\n",
    " 'chopped',\n",
    " \"pop's\",\n",
    " 'chop-chop',\n",
    " 'stopped',\n",
    " 'copped']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hair_phonemes: ['hairr',\n",
    " 'hehir',\n",
    " \"o'hair\",\n",
    " 'hehl',\n",
    " \"hair's\",\n",
    " 'hehn',\n",
    " 'herin',\n",
    " 'deherrera',\n",
    " 'rahe',\n",
    " 'harry',\n",
    " 'herrero',\n",
    " 'haired']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naked_phonemes: ['naked',\n",
    " 'likud',\n",
    " 'mitigate',\n",
    " 'indicated',\n",
    " 'mittag',\n",
    " 'dedicated',\n",
    " 'syndicate',\n",
    " 'mcelligott',\n",
    " 'wreckage',\n",
    " 'indicate',\n",
    " 'legate',\n",
    " 'mitigating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "girls_phonemes: [\"girl's\",\n",
    " \"berle's\",\n",
    " 'girds',\n",
    " 'girl',\n",
    " \"birds'\",\n",
    " 'girdler',\n",
    " 'gurnards',\n",
    " 'gird',\n",
    " 'burglars',\n",
    " 'girders',\n",
    " 'collards',\n",
    " 'curls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "before\n",
      "of\n",
      "the\n",
      "tip\n",
      "out.\n",
      "make\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-5db5161fc2de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitials_ft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "#print(initials_bj['a'][0])\n",
    "#print(initials_bj['b'][0],initials_bj['o'][0] )\n",
    "\n",
    "count=0\n",
    "for ch in seed:\n",
    "    print(initials_ft[ch][count])\n",
    "    count = count +1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A \n",
    "branching out the tree of my life every saw story \n",
    "purple I the \n",
    "One fig \n",
    "South Ee like From - like of a the husband in names green. \n",
    "\n",
    "And \n",
    "before other tip the offbeat me lovers editor Socrates saw\n",
    "post I these \n",
    "Olympic fat \n",
    "Sitting Europe lady fig - losing out a the happy I names Gee. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      " bird-eyed off the the our me let Everything stopped said\n",
      " people ice-cubes to\n",
      " on flash,\n",
      " said embroidered loopy Five - lot, of a the had I Nolan girl.\n",
      "\n",
      "a\n",
      " box one, trouble the out Mrs love easy skirt said,\n",
      " published. introduced the\n",
      " one fine\n",
      " smudge-fronted execution. laughed. for - let only a to he in next-door. grills.\n",
      "\n",
      "and\n",
      " bathroom. one the the one my like eyes. sick street\n",
      " put in the\n",
      " of fresh\n",
      " said emergencies. long fasten - lady of at that.' had I New German.\n",
      "\n",
      "age\n",
      " bit one thought the one moaning liquor Eve stone showed\n",
      " polar image to\n",
      " of fern,\n",
      " slid empty-handed. lingered For - last of and tarty heard I noise going.\n",
      "\n",
      "a\n",
      " bill of the to own. my large Elly?' simply said.\n",
      " padded I their\n",
      " or felt\n",
      " smoke-dark enjoyed liked fine - last over accounts, The her I never girls.\n",
      "\n",
      "all\n",
      " better own the the out mean lifted exactly some?' so\n",
      " place I to\n",
      " odd, from\n",
      " she earbones letter for - large of abbreviations thought had its nod, gave.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "        \"origin\": \"#a_words#\\n #b_words# #o_words# #t_words# #t_words# #o_words# #m_words# #l_words# #e_words# #s_words# #s_words#\\n #p_words# #i_words# #t_words#\\n #o_words# #f_words#\\n #s_words# #e_words# #l_words# #f_words# - #l_words# #o_words# #a_words# #t_words# #h_words# #i_words# #n_words# #g_words#.\"\n",
    "    ,\n",
    "        \"a_words\": initials_bj['a'], \n",
    "        \"b_words\": b_words_bj,\n",
    "        \"o_words\": o_words_bj,\n",
    "        \"t_words\": t_words_bj,\n",
    "        \"m_words\": m_words_bj,\n",
    "        \"l_words\": l_words_bj,\n",
    "        \"e_words\": e_words_bj,\n",
    "        \"s_words\": s_words_bj,\n",
    "        \"p_words\": p_words_bj, \n",
    "        \"i_words\": i_words_bj,\n",
    "        \"f_words\": f_words_bj,\n",
    "        \"h_words\": h_words_bj,\n",
    "        \"n_words\": n_words_bj,\n",
    "        \"g_words\": g_words_bj\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['being',\n",
       " 'but',\n",
       " 'be',\n",
       " 'being',\n",
       " 'burned',\n",
       " 'be',\n",
       " 'bad',\n",
       " 'By',\n",
       " 'bottom',\n",
       " 'blew',\n",
       " 'behind',\n",
       " 'bacon',\n",
       " 'breakfast',\n",
       " 'behind',\n",
       " 'Buddy',\n",
       " 'black,',\n",
       " 'balloon',\n",
       " 'because',\n",
       " 'been',\n",
       " 'buy',\n",
       " 'be',\n",
       " 'be',\n",
       " 'be',\n",
       " 'bought',\n",
       " \"Bloomingdale's\",\n",
       " 'black',\n",
       " 'belt',\n",
       " 'black',\n",
       " 'bodice',\n",
       " 'big,',\n",
       " 'bone',\n",
       " 'be',\n",
       " 'bumped',\n",
       " 'back',\n",
       " 'been',\n",
       " 'but',\n",
       " 'by',\n",
       " 'blurbs,',\n",
       " 'bonuses,',\n",
       " 'ballet',\n",
       " 'brown',\n",
       " 'brown',\n",
       " 'brown',\n",
       " 'brush,',\n",
       " 'basin',\n",
       " 'blue',\n",
       " 'big',\n",
       " 'box',\n",
       " 'because',\n",
       " 'but',\n",
       " 'be',\n",
       " 'but',\n",
       " 'brought',\n",
       " 'baby',\n",
       " 'both',\n",
       " 'be',\n",
       " 'be',\n",
       " 'bored',\n",
       " 'Bermuda',\n",
       " 'bored',\n",
       " 'bored',\n",
       " 'bored',\n",
       " 'bored',\n",
       " 'bored',\n",
       " 'Brazil.',\n",
       " 'been',\n",
       " 'big',\n",
       " 'but',\n",
       " 'back',\n",
       " 'before.',\n",
       " 'bright',\n",
       " 'blue',\n",
       " 'but',\n",
       " 'breath.',\n",
       " 'bawled',\n",
       " 'bothering',\n",
       " 'by',\n",
       " 'bed',\n",
       " 'board,',\n",
       " 'best-selling',\n",
       " 'beachcoats,',\n",
       " 'but',\n",
       " 'by',\n",
       " 'break',\n",
       " 'between',\n",
       " 'bet',\n",
       " 'before',\n",
       " 'boss,',\n",
       " 'brains,',\n",
       " 'business.',\n",
       " 'bed',\n",
       " 'but',\n",
       " 'bed',\n",
       " 'but',\n",
       " 'bother',\n",
       " 'Betsy.',\n",
       " 'Betsy',\n",
       " 'bouncing',\n",
       " 'blonde',\n",
       " 'blue-chinned',\n",
       " 'build',\n",
       " 'Betsy',\n",
       " 'Beauty',\n",
       " 'Betsy',\n",
       " 'B.H.',\n",
       " 'Betsy',\n",
       " 'Betsy',\n",
       " \"Betsy,'\",\n",
       " 'Betsy',\n",
       " 'base',\n",
       " 'bedside',\n",
       " 'Buddy',\n",
       " 'but',\n",
       " 'by',\n",
       " 'but',\n",
       " 'bones.',\n",
       " 'back',\n",
       " \"Betsy's\",\n",
       " 'bulged',\n",
       " 'below,',\n",
       " 'bronzy',\n",
       " 'black',\n",
       " 'buying',\n",
       " 'bra',\n",
       " 'but',\n",
       " 'boy',\n",
       " 'barely',\n",
       " 'been',\n",
       " 'but',\n",
       " 'being',\n",
       " 'blue',\n",
       " 'black',\n",
       " 'boots',\n",
       " 'bar',\n",
       " 'been',\n",
       " 'between',\n",
       " 'big,',\n",
       " 'blurted,',\n",
       " 'blas',\n",
       " \"boring,'\",\n",
       " 'both',\n",
       " 'bar',\n",
       " 'been',\n",
       " 'back',\n",
       " 'burst',\n",
       " 'but',\n",
       " 'be',\n",
       " 'besides',\n",
       " 'big',\n",
       " 'been',\n",
       " 'been',\n",
       " 'bar.',\n",
       " 'brakes',\n",
       " 'by',\n",
       " 'behind',\n",
       " 'bumped',\n",
       " 'back',\n",
       " 'bill',\n",
       " 'but',\n",
       " 'bridesmaids.',\n",
       " 'bar',\n",
       " 'bit',\n",
       " 'but',\n",
       " 'by',\n",
       " 'bar',\n",
       " 'bar.',\n",
       " 'before',\n",
       " 'Buddy',\n",
       " 'boys',\n",
       " 'buy',\n",
       " 'boys',\n",
       " 'Buddy',\n",
       " 'buying',\n",
       " 'bottle',\n",
       " 'because',\n",
       " 'be',\n",
       " 'being',\n",
       " 'by',\n",
       " 'blue',\n",
       " 'be',\n",
       " 'bar',\n",
       " 'be',\n",
       " 'but',\n",
       " 'break',\n",
       " 'burst',\n",
       " 'bare',\n",
       " 'bleached',\n",
       " 'blonde',\n",
       " 'be',\n",
       " 'Boston.',\n",
       " 'blue',\n",
       " 'blue',\n",
       " 'Black',\n",
       " 'brown,',\n",
       " 'Blue',\n",
       " 'back',\n",
       " 'by',\n",
       " 'bottom',\n",
       " 'be',\n",
       " 'began',\n",
       " 'but',\n",
       " 'better',\n",
       " 'but',\n",
       " 'be',\n",
       " 'being',\n",
       " 'but',\n",
       " 'big',\n",
       " 'bills',\n",
       " 'but',\n",
       " 'baby',\n",
       " 'but',\n",
       " 'built',\n",
       " 'broaden',\n",
       " 'bar',\n",
       " 'bearskins',\n",
       " 'beds',\n",
       " 'buffalo',\n",
       " 'boots',\n",
       " 'been',\n",
       " 'born',\n",
       " 'bred',\n",
       " 'be',\n",
       " \"bet,'\",\n",
       " 'by',\n",
       " 'back',\n",
       " 'bar',\n",
       " 'big',\n",
       " 'began',\n",
       " 'bottles.',\n",
       " 'balancing',\n",
       " 'Big',\n",
       " 'by',\n",
       " 'big',\n",
       " 'both',\n",
       " 'beds',\n",
       " 'businessmen',\n",
       " 'belly-dancer,',\n",
       " 'but',\n",
       " 'back',\n",
       " 'bed',\n",
       " 'bearskin',\n",
       " 'back',\n",
       " 'bed',\n",
       " 'below',\n",
       " 'bit,',\n",
       " 'boomed,',\n",
       " 'black',\n",
       " 'bang',\n",
       " 'back',\n",
       " 'bearskin',\n",
       " 'back',\n",
       " \"bitch!'\",\n",
       " 'breasts',\n",
       " 'brown',\n",
       " 'belly-down',\n",
       " 'both',\n",
       " 'bite',\n",
       " 'before',\n",
       " 'by',\n",
       " 'both',\n",
       " 'banister',\n",
       " 'been',\n",
       " 'been',\n",
       " 'but',\n",
       " 'because',\n",
       " 'be',\n",
       " 'by',\n",
       " 'barn',\n",
       " 'ballroom',\n",
       " 'brushing',\n",
       " 'buildings',\n",
       " 'blocks',\n",
       " 'by',\n",
       " 'blocks',\n",
       " 'blocks',\n",
       " 'breath,',\n",
       " 'but',\n",
       " 'because',\n",
       " 'bothered',\n",
       " 'booth',\n",
       " 'button',\n",
       " 'big,',\n",
       " 'but',\n",
       " 'button',\n",
       " 'By',\n",
       " 'balanced',\n",
       " 'bridges',\n",
       " 'behind',\n",
       " 'buildings',\n",
       " 'but',\n",
       " 'blinking,',\n",
       " 'but',\n",
       " 'been',\n",
       " 'bedside',\n",
       " 'but',\n",
       " 'be',\n",
       " 'but',\n",
       " 'Buddy',\n",
       " 'Buddy,',\n",
       " \"Buddy's\",\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'bureau',\n",
       " 'ball',\n",
       " 'between',\n",
       " 'bed-sheets',\n",
       " 'but',\n",
       " 'bath.',\n",
       " 'be',\n",
       " 'bath',\n",
       " 'but',\n",
       " 'be',\n",
       " \"bath.'\",\n",
       " 'bath.',\n",
       " 'be',\n",
       " 'barely',\n",
       " 'by',\n",
       " 'bathtub',\n",
       " 'bath.',\n",
       " 'believe',\n",
       " 'baptism',\n",
       " 'but',\n",
       " 'bath',\n",
       " 'back',\n",
       " 'big,',\n",
       " 'bath-towels',\n",
       " 'baby.',\n",
       " 'been',\n",
       " 'because',\n",
       " 'bumping',\n",
       " 'balanced',\n",
       " 'be',\n",
       " 'but',\n",
       " 'blinked',\n",
       " 'bright',\n",
       " 'but',\n",
       " 'between',\n",
       " 'because',\n",
       " 'blonde',\n",
       " 'black',\n",
       " 'back',\n",
       " 'because',\n",
       " 'bed',\n",
       " 'body',\n",
       " 'budge',\n",
       " 'back',\n",
       " 'bed.',\n",
       " 'back',\n",
       " 'but',\n",
       " 'brown',\n",
       " 'blonde',\n",
       " 'bog,',\n",
       " 'back.',\n",
       " 'but',\n",
       " 'be',\n",
       " 'Betsy',\n",
       " 'Betsy',\n",
       " 'back',\n",
       " 'bring',\n",
       " 'body',\n",
       " 'before',\n",
       " 'by',\n",
       " 'but',\n",
       " 'banquet',\n",
       " 'beef',\n",
       " 'bowl',\n",
       " 'black',\n",
       " 'breakfast',\n",
       " 'bitter',\n",
       " 'Before',\n",
       " 'Buddy',\n",
       " 'but',\n",
       " 'been',\n",
       " 'butter',\n",
       " 'because',\n",
       " 'bunch',\n",
       " 'bald',\n",
       " 'banquet',\n",
       " 'because',\n",
       " 'before',\n",
       " 'big',\n",
       " 'been',\n",
       " 'bright',\n",
       " 'because',\n",
       " 'be',\n",
       " 'behind',\n",
       " 'behind',\n",
       " 'bowed',\n",
       " 'bowls',\n",
       " 'bowl',\n",
       " 'between',\n",
       " 'because',\n",
       " 'Betsy,',\n",
       " 'be',\n",
       " 'by',\n",
       " 'bread-and-butter',\n",
       " 'Besides,',\n",
       " 'bowl',\n",
       " 'Betsy,',\n",
       " 'bring',\n",
       " 'brother',\n",
       " 'by',\n",
       " 'because',\n",
       " 'bone',\n",
       " 'bread.',\n",
       " 'by',\n",
       " 'bad-mannered',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'by',\n",
       " 'back',\n",
       " 'bowl',\n",
       " 'be',\n",
       " 'Betsy',\n",
       " 'bring',\n",
       " 'bottom',\n",
       " 'briefcase',\n",
       " 'by',\n",
       " 'bland',\n",
       " 'Betsy,',\n",
       " 'black',\n",
       " 'Betsy',\n",
       " 'bought',\n",
       " 'bunch',\n",
       " 'big',\n",
       " \"bus.'\",\n",
       " 'Betsy.',\n",
       " 'by',\n",
       " 'Betsy',\n",
       " 'beauty.',\n",
       " 'but',\n",
       " 'by',\n",
       " 'bits',\n",
       " 'bizarre',\n",
       " 'been',\n",
       " 'by',\n",
       " 'Betsy',\n",
       " 'been',\n",
       " 'but',\n",
       " 'but',\n",
       " 'be',\n",
       " 'Betsy',\n",
       " 'been',\n",
       " 'bed',\n",
       " 'bed',\n",
       " 'bald,',\n",
       " 'but',\n",
       " 'bed.',\n",
       " 'but',\n",
       " 'bustling',\n",
       " 'back',\n",
       " 'bed',\n",
       " 'blank,',\n",
       " 'bigger',\n",
       " 'bigger',\n",
       " 'burst',\n",
       " 'bit',\n",
       " 'bone-coloured',\n",
       " 'brutal',\n",
       " 'be',\n",
       " 'be',\n",
       " 'but',\n",
       " 'Betsy.',\n",
       " 'Betsy',\n",
       " 'brandy',\n",
       " 'because',\n",
       " 'bit',\n",
       " 'but',\n",
       " 'behind',\n",
       " 'back',\n",
       " 'but',\n",
       " 'be',\n",
       " 'by',\n",
       " 'Board,',\n",
       " 'biggest',\n",
       " 'best',\n",
       " 'but',\n",
       " 'balk',\n",
       " 'balk',\n",
       " 'bit',\n",
       " 'before',\n",
       " 'bother',\n",
       " 'big',\n",
       " 'be',\n",
       " 'books',\n",
       " 'books',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'bit',\n",
       " 'been',\n",
       " 'by',\n",
       " 'black',\n",
       " 'brother',\n",
       " 'Berlin',\n",
       " 'book,',\n",
       " 'black,',\n",
       " 'barbed-wire',\n",
       " 'back',\n",
       " 'bright',\n",
       " 'be',\n",
       " 'better',\n",
       " 'because',\n",
       " 'but',\n",
       " 'botany',\n",
       " 'being',\n",
       " 'botanist',\n",
       " 'because',\n",
       " 'big',\n",
       " 'Botany',\n",
       " 'because',\n",
       " 'bread',\n",
       " 'blue',\n",
       " 'ball.',\n",
       " 'ball',\n",
       " 'bottom.',\n",
       " 'blackboard',\n",
       " 'book',\n",
       " 'back',\n",
       " 'book',\n",
       " 'brick-red',\n",
       " 'book',\n",
       " 'by',\n",
       " 'balls',\n",
       " 'bells',\n",
       " 'by',\n",
       " 'bunch',\n",
       " 'be',\n",
       " 'because',\n",
       " 'but',\n",
       " 'but',\n",
       " 'breathe',\n",
       " 'blackboard,',\n",
       " 'be',\n",
       " 'because',\n",
       " 'big',\n",
       " 'brain',\n",
       " 'by',\n",
       " 'bit',\n",
       " 'by',\n",
       " 'but',\n",
       " 'beauty',\n",
       " 'bear',\n",
       " 'but',\n",
       " 'Board',\n",
       " 'by',\n",
       " 'bottom',\n",
       " 'big,',\n",
       " 'blue',\n",
       " 'by',\n",
       " 'by',\n",
       " 'back',\n",
       " 'bright',\n",
       " 'but',\n",
       " 'because',\n",
       " 'back',\n",
       " 'ball',\n",
       " 'billowed',\n",
       " 'before',\n",
       " 'being',\n",
       " \"Betsy's\",\n",
       " 'be',\n",
       " 'by',\n",
       " 'Betsy',\n",
       " 'bit',\n",
       " 'bought',\n",
       " 'by',\n",
       " 'bring',\n",
       " 'be',\n",
       " 'because',\n",
       " 'but',\n",
       " 'banquet',\n",
       " 'bright',\n",
       " 'blouse,',\n",
       " 'briefly',\n",
       " 'but',\n",
       " 'be',\n",
       " 'because',\n",
       " 'bowl',\n",
       " 'between',\n",
       " 'brought',\n",
       " 'back',\n",
       " 'bloomed',\n",
       " 'benefactress.',\n",
       " 'Bette',\n",
       " 'bicycled',\n",
       " 'by',\n",
       " 'bus',\n",
       " 'before',\n",
       " 'be',\n",
       " 'books',\n",
       " 'books',\n",
       " 'beginning',\n",
       " 'bleak,',\n",
       " 'books',\n",
       " 'been',\n",
       " 'blossoms',\n",
       " 'be',\n",
       " 'bit',\n",
       " 'blossoms.',\n",
       " 'but',\n",
       " 'Brazil.',\n",
       " 'Betsy',\n",
       " 'bun',\n",
       " 'blonde',\n",
       " 'but',\n",
       " 'black-haired',\n",
       " 'but',\n",
       " 'big,',\n",
       " 'broad-shouldered',\n",
       " 'boneheads',\n",
       " 'blue',\n",
       " 'ballroom,',\n",
       " 'because',\n",
       " 'began',\n",
       " 'black',\n",
       " 'back,',\n",
       " 'back',\n",
       " 'Betsy',\n",
       " 'Betsy',\n",
       " 'barely',\n",
       " 'back',\n",
       " 'boots',\n",
       " 'because',\n",
       " 'ballooning',\n",
       " 'Betsy',\n",
       " 'bloom',\n",
       " 'by',\n",
       " 'Betsy',\n",
       " 'back',\n",
       " 'be',\n",
       " 'better',\n",
       " 'But',\n",
       " 'Betsy',\n",
       " 'better',\n",
       " 'But',\n",
       " 'behind',\n",
       " 'bed,',\n",
       " 'bathrobe',\n",
       " 'blue',\n",
       " 'bathroom.',\n",
       " 'Betsy',\n",
       " 'behind',\n",
       " 'bathroom',\n",
       " 'both.',\n",
       " 'bowl',\n",
       " 'by',\n",
       " 'be',\n",
       " 'bones',\n",
       " 'banging',\n",
       " 'big',\n",
       " 'bad',\n",
       " 'bathroom',\n",
       " 'bathroom',\n",
       " 'But',\n",
       " 'banging',\n",
       " 'bit',\n",
       " 'bungled',\n",
       " 'bowl',\n",
       " 'be',\n",
       " 'black',\n",
       " 'be',\n",
       " 'blue',\n",
       " 'bathrobe',\n",
       " 'be',\n",
       " 'belong',\n",
       " 'black',\n",
       " 'but',\n",
       " 'bed',\n",
       " 'boomp',\n",
       " 'boomp',\n",
       " 'being',\n",
       " 'began',\n",
       " 'by,',\n",
       " 'by',\n",
       " 'bed',\n",
       " 'back,',\n",
       " 'bedside',\n",
       " 'briefly.',\n",
       " 'been',\n",
       " 'blank',\n",
       " 'by',\n",
       " \"better.'\",\n",
       " 'been',\n",
       " 'been',\n",
       " 'butter',\n",
       " 'behind',\n",
       " 'blonde',\n",
       " 'behind',\n",
       " 'but',\n",
       " 'been',\n",
       " 'Betsy',\n",
       " 'bent',\n",
       " 'broth.',\n",
       " 'be',\n",
       " 'being',\n",
       " 'brilliant',\n",
       " 'blanket',\n",
       " 'bland',\n",
       " 'big',\n",
       " 'back.',\n",
       " 'big',\n",
       " 'began',\n",
       " 'because',\n",
       " 'box',\n",
       " 'be',\n",
       " 'but',\n",
       " 'brought',\n",
       " 'begged.',\n",
       " 'back',\n",
       " 'book',\n",
       " 'Best',\n",
       " 'book',\n",
       " 'box.',\n",
       " 'both',\n",
       " 'burst',\n",
       " 'by',\n",
       " 'bottom',\n",
       " 'black',\n",
       " 'bother',\n",
       " 'but',\n",
       " 'bad',\n",
       " 'be',\n",
       " 'but',\n",
       " 'but',\n",
       " 'both',\n",
       " 'big',\n",
       " 'but',\n",
       " 'both',\n",
       " 'Boston',\n",
       " 'Business',\n",
       " 'bite',\n",
       " 'bite',\n",
       " 'been',\n",
       " 'bite',\n",
       " 'bite',\n",
       " 'back',\n",
       " 'building',\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'Because',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'boy',\n",
       " 'before',\n",
       " 'beautiful',\n",
       " 'by',\n",
       " 'because',\n",
       " 'before',\n",
       " 'breakfast.',\n",
       " 'bed',\n",
       " 'breakfast',\n",
       " 'but',\n",
       " 'brought',\n",
       " 'bald',\n",
       " \"bellhop's\",\n",
       " 'bellhop',\n",
       " 'began',\n",
       " 'back',\n",
       " 'bringing',\n",
       " 'before',\n",
       " 'behind',\n",
       " 'behaviour,',\n",
       " 'by',\n",
       " 'bellhop',\n",
       " 'but',\n",
       " \"back.'\",\n",
       " 'But',\n",
       " 'by',\n",
       " 'broke',\n",
       " 'beside',\n",
       " 'book',\n",
       " 'bedjacket',\n",
       " 'basket',\n",
       " 'basket',\n",
       " 'best',\n",
       " 'bottom',\n",
       " 'between',\n",
       " 'beautiful',\n",
       " \"bird's\",\n",
       " 'branch',\n",
       " 'bird',\n",
       " 'backs',\n",
       " 'but',\n",
       " 'both',\n",
       " 'be',\n",
       " 'between',\n",
       " 'black',\n",
       " 'beautiful',\n",
       " 'big',\n",
       " 'Buddy',\n",
       " 'but',\n",
       " 'bird',\n",
       " 'but',\n",
       " 'baby',\n",
       " 'bed',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'by',\n",
       " 'been',\n",
       " 'Buddy',\n",
       " 'been',\n",
       " 'blond',\n",
       " 'blue',\n",
       " 'Buddy',\n",
       " 'beginnings',\n",
       " 'Buddy,',\n",
       " 'back',\n",
       " 'back',\n",
       " 'bed,',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'because',\n",
       " 'bit',\n",
       " 'better',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'blue',\n",
       " 'Buddy',\n",
       " 'both',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'Buddy',\n",
       " 'by',\n",
       " 'blister',\n",
       " 'being',\n",
       " 'bit.',\n",
       " 'Buddy',\n",
       " 'but',\n",
       " 'beat',\n",
       " 'because',\n",
       " 'blind',\n",
       " 'best',\n",
       " 'buck',\n",
       " 'bad',\n",
       " 'bookso',\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'blue',\n",
       " 'because',\n",
       " 'Buddy',\n",
       " 'big',\n",
       " 'by',\n",
       " 'Buddy',\n",
       " 'big',\n",
       " 'breathy',\n",
       " 'big',\n",
       " 'began',\n",
       " 'Buddy',\n",
       " 'bicycle',\n",
       " 'been',\n",
       " 'best',\n",
       " 'Buddy',\n",
       " 'better',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'because',\n",
       " 'blue',\n",
       " 'by',\n",
       " 'Buddy',\n",
       " 'bright',\n",
       " 'book.',\n",
       " 'Buddy',\n",
       " 'black,',\n",
       " 'back',\n",
       " 'because',\n",
       " 'beds.',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'beautiful',\n",
       " 'behind',\n",
       " 'behind',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'back.',\n",
       " 'been',\n",
       " 'bad',\n",
       " 'both',\n",
       " \"boys,'\",\n",
       " 'Buddy',\n",
       " 'boy',\n",
       " 'back',\n",
       " 'Buddy',\n",
       " 'baby',\n",
       " 'born.',\n",
       " 'begging',\n",
       " 'Buddy',\n",
       " 'by',\n",
       " 'Buddy',\n",
       " 'bother',\n",
       " 'bit.',\n",
       " 'Buddy',\n",
       " 'big',\n",
       " 'bottles',\n",
       " 'babies',\n",
       " 'before',\n",
       " 'born.',\n",
       " 'baby',\n",
       " 'bottle',\n",
       " 'bent',\n",
       " 'body',\n",
       " 'baby',\n",
       " 'bottle',\n",
       " 'bigger',\n",
       " 'baby',\n",
       " 'bigger',\n",
       " 'baby',\n",
       " 'bottle',\n",
       " 'baby',\n",
       " 'be',\n",
       " \"Buddy's\",\n",
       " 'burning',\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'burning',\n",
       " 'back',\n",
       " 'before',\n",
       " 'Buddy',\n",
       " 'beautiful',\n",
       " 'black',\n",
       " 'bell',\n",
       " 'baby',\n",
       " 'born.',\n",
       " 'Buddy',\n",
       " 'big',\n",
       " 'Buddy',\n",
       " 'busy',\n",
       " 'be',\n",
       " 'be',\n",
       " 'because',\n",
       " 'big',\n",
       " 'By',\n",
       " 'Buddy',\n",
       " 'baby',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'beading',\n",
       " 'Buddy',\n",
       " 'babies',\n",
       " 'before',\n",
       " 'bustle',\n",
       " 'big',\n",
       " 'baby',\n",
       " 'be',\n",
       " 'Buddy',\n",
       " 'Buddy',\n",
       " 'by',\n",
       " 'Buddy',\n",
       " 'by',\n",
       " 'body',\n",
       " 'but',\n",
       " 'baby',\n",
       " 'being',\n",
       " 'born',\n",
       " 'Buddy',\n",
       " 'because',\n",
       " 'bit',\n",
       " 'baby,',\n",
       " 'because',\n",
       " 'bad',\n",
       " 'been,',\n",
       " 'blind,',\n",
       " 'between',\n",
       " \"baby's\",\n",
       " 'Buddy',\n",
       " 'But',\n",
       " \"baby's\",\n",
       " 'blood',\n",
       " 'began',\n",
       " 'bright',\n",
       " 'baby',\n",
       " 'blue',\n",
       " 'blood,',\n",
       " 'baby',\n",
       " 'blue',\n",
       " 'baby',\n",
       " 'boy.',\n",
       " 'baby',\n",
       " 'Buddy',\n",
       " 'but',\n",
       " 'baby',\n",
       " 'born',\n",
       " \"baby's\",\n",
       " 'boy,',\n",
       " 'but',\n",
       " 'Buddy',\n",
       " 'babies.',\n",
       " 'baby',\n",
       " 'but',\n",
       " 'Buddy',\n",
       " \"baby's\",\n",
       " 'back',\n",
       " \"Buddy's\",\n",
       " 'bare',\n",
       " 'bare',\n",
       " ...]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_words_bj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and\n",
      " But own This the out made like Europe, sandwich. stepped\n",
      " put interpreter the\n",
      " old feeling\n",
      " she Egos like for - lab of at them had I night graveyard.\n",
      "\n",
      "and\n",
      " been only to the on my leg. eye sack set\n",
      " perfect in the\n",
      " on from\n",
      " suddenly early laughed. flash - lively, our also The he Irwin no given.\n",
      "\n",
      "and\n",
      " but of that the on many life. electrocuted she so,\n",
      " pink. I told\n",
      " of floated\n",
      " smile, Esther?' like filling - lace, on ash-coloured the have I nurse go.\n",
      "\n",
      "and\n",
      " but of towel, to over myself lips entrance something. somebody\n",
      " potsbaked interview, true.\n",
      " open felt\n",
      " summer egg low from. - long of and The here in nurses, girl.\n",
      "\n",
      "a\n",
      " been over town thought on mother living expect something stupid\n",
      " Philomena in that,\n",
      " of first\n",
      " seems even. light feet. - like of all the heavier. I'll nine go.\n",
      "\n",
      "about\n",
      " be of them There or mere lobby endless stark Shepherd\n",
      " property, I they\n",
      " one for\n",
      " semi-opaque eye last fifteen - like or a the her I never glittered,.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rules = {\n",
    "        \"origin\": \"#a_words#\\n #b_words# #o_words# #t_words# #t_words# #o_words# #m_words# #l_words# #e_words# #s_words# #s_words#\\n #p_words# #i_words# #t_words#\\n #o_words# #f_words#\\n #s_words# #e_words# #l_words# #f_words# - #l_words# #o_words# #a_words# #t_words# #h_words# #i_words# #n_words# #g_words#.\"\n",
    "    ,\n",
    "        \"a_words\": a_words_bj, \n",
    "        \"b_words\": b_words_bj,\n",
    "        \"o_words\": o_words_bj,\n",
    "        \"t_words\": t_words_bj,\n",
    "        \"m_words\": m_words_bj,\n",
    "        \"l_words\": l_words_bj,\n",
    "        \"e_words\": e_words_bj,\n",
    "        \"s_words\": s_words_bj,\n",
    "        \"p_words\": p_words_bj, \n",
    "        \"i_words\": i_words_bj,\n",
    "        \"f_words\": f_words_bj,\n",
    "        \"h_words\": h_words_bj,\n",
    "        \"n_words\": n_words_bj,\n",
    "        \"g_words\": g_words_bj\n",
    "}\n",
    "grammar = tracery.Grammar(rules)\n",
    "grammar.add_modifiers(base_english)\n",
    "print(grammar.flatten(\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"+\"#origin#\"+\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'saw', 'my', 'life', 'branching', 'out', 'before', 'me', 'like', 'the', 'green', 'fig', 'tree', 'in', 'the', 'story.', 'From', 'the', 'tip', 'of', 'every', 'branch,', 'like', 'a', 'fat', 'purple', 'fig,', 'a', 'wonderful', 'future', 'beckoned', 'and', 'winked.', 'One', 'fig', 'was', 'a', 'husband', 'and', 'a', 'happy', 'home', 'and', 'children,', 'and', 'another', 'fig', 'was', 'a', 'famous', 'poet', 'and', 'another', 'fig', 'was', 'a', 'brilliant', 'professor,', 'and', 'another', 'fig', 'was', 'Ee', 'Gee,', 'the', 'amazing', 'editor,', 'and', 'another', 'fig', 'was', 'Europe', 'and', 'Africa', 'and', 'South', 'America,', 'and', 'another', 'fig', 'was', 'Constantin', 'and', 'Socrates', 'and', 'Attila', 'and', 'a', 'pack', 'of', 'other', 'lovers', 'with', 'queer', 'names', 'and', 'offbeat', 'professions,', 'and', 'another', 'fig', 'was', 'an', 'Olympic', 'lady', 'crew', 'champion,', 'and', 'beyond', 'and', 'above', 'these', 'figs', 'were', 'many', 'more', 'figs', 'I', \"couldn't\", 'quite', 'make', 'out.', 'I', 'saw', 'myself', 'sitting', 'in', 'the', 'crotch', 'of', 'this', 'fig', 'tree,', 'starving', 'to', 'death,', 'just', 'because', 'I', \"couldn't\", 'make', 'up', 'my', 'mind', 'which', 'of', 'the', 'figs', 'I', 'would', 'choose.', 'I', 'wanted', 'each', 'and', 'every', 'one', 'of', 'them,', 'but', 'choosing', 'one', 'meant', 'losing', 'all', 'the', 'rest,', 'and,', 'as', 'I', 'sat', 'there,', 'unable', 'to', 'decide,', 'the', 'figs', 'began', 'to', 'wrinkle', 'and', 'go', 'black,', 'and,', 'one', 'by', 'one,', 'they', 'plopped', 'to', 'the', 'ground', 'at', 'my', 'feet.']\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
